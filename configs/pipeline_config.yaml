# Qwen2.5 Quantization Pipeline Configuration
# Pipeline: PiSSA -> SpinQuant -> GaLore

# Model Configuration
model_name: "Qwen/Qwen2.5-7B-Instruct"

# Output Configuration
output_dir: "outputs"
log_dir: "logs"

# Optional experiment trackers (GaLore training)
use_tensorboard: true
use_wandb: true
wandb:
  mode: "online"  # offline|online|disabled
  project: "DLProj"
  entity: "yangchen0305"

# Training Configuration (bounded defaults)
seed: 42
num_epochs: 1
batch_size: 4
gradient_accumulation_steps: 2
warmup_steps: 100
logging_steps: 10
save_steps: 500
save_total_limit: 3

# Optional cap on total optimizer steps (overrides epochs if set).
max_steps: 800

# Dataset Configuration
# NOTE: This dataset is used for *adapter training* in the pipeline.
dataset: "c4"
dataset_split: "train"
max_samples: 2000
max_length: 256

# PiSSA Configuration
pissa:
  rank: 64
  alpha: 128
  dropout: 0.05
  target_modules:
    - "q_proj"
    - "k_proj"
    - "v_proj"
    - "o_proj"
    - "gate_proj"
    - "up_proj"
    - "down_proj"
  bias: "none"

# SpinQuant Configuration
spinquant:
  bits: 8  # Options: 4, 8
  # Keep some rotation effect without per-layer optimization taking forever.
  # Use Hadamard (fast, fixed) instead of learned Givens sweeps.
  backend: "hadamard"
  skip_rotations: false
  double_quant: true
  quant_type: "nf4"  # Options: "nf4", "fp4"
  group_size: 128
  symmetric: false
  backend: "blockwise_givens"
  block_size: 64
  num_steps: 5  # (unused for hadamard)
  lr: 0.05
  num_sweeps: 2
  max_layers: 4
  use_bnb_quantization: true
  use_activation_objective: true
  calibration_vectors_per_layer: 256
  keep_fp16_modules:
    - "input_embeddings"
    - "output_embeddings"

# GaLore Configuration
galore:
  rank: 128
  learning_rate: 1.0e-4
  weight_decay: 0.01
  update_proj_gap: 200
  scale: 0.25
  proj_type: "std"

# Optional: post-quant adapter distillation
distill:
  enabled: false
  alpha: 0.5
  temperature: 2.0

# GaLore-like gradient projection (projection-space updates)
projection:
  enabled: true
  rank: 64
  update_gap: 200
  drift_threshold: 0.35

\section{Conclusion}
\label{sec:conclusion}

This paper presented \method, a practical pipeline for adapting and serving quantized LLMs.
By combining PiSSA-initialized low-rank adapters, SpinQuant-inspired orthogonal mixing before quantization, and GaLore-style projected-gradient training, we align training-time decisions with quantized deployment constraints.
The accompanying benchmark harness and configuration provide a reproducible path to evaluate this trade-off on difficult reasoning tasks.

